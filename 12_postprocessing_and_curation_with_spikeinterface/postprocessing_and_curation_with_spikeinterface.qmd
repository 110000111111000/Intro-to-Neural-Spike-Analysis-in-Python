---
title: "Postprocessing and Curation with SpikeInterface"
engine: Jupyter
format: ipynb
filter:
    - assign
    - solution
execute: 
  cache: true
number-sections: true
number-depth: 2
---

```{python}
import numpy as np
from matplotlib import pyplot as plt
import spikeinterface.full as si
import probeinterface as pi
%matplotlib inline
```

Download the data for this session (this may take a moment)
```{python}
import os
import zipfile
import requests

fnames = ["openephys_preprocessed", "results_KS4", "results_SPC", "results_TDC"]
urls = [
    "https://uni-bonn.sciebo.de/s/2LbWWs3VPVrQkLO",
    "https://uni-bonn.sciebo.de/s/26X6qhAAYq1uJfZ",
    "https://uni-bonn.sciebo.de/s/FnRPj7EQSYXFIEg",
    "https://uni-bonn.sciebo.de/s/EkdnDNhvF68HC9D",
]

if not os.path.exists("../data"):
    os.mkdir("../data")

for url, fname in zip(urls, fnames):
    if not os.path.exists(f"../data/{fname}"):
        response = requests.get(f"{url}/download")
        with open(f"{fname}.zip", "wb") as file:
            file.write(response.content)

        with zipfile.ZipFile(f"{fname}.zip", "r") as zip_ref:
            zip_ref.extractall(f"../data/{fname}")
        os.remove(f"{fname}.zip")
```

## Extracting and Visualizing Spike Waveforms

| Code | Description |
| --- | --- |
| `rec = si.load_extractor("mydir")` | Load the recording extractor stored in the folder `"mydir"` |
| `sorting = si.read_sorter_folder("results_SPC")` | Load the spike sorting results stored in the folder `"/results_SPC"` |
| `analyzer = si.create_sorting_analyzer(sorting, recording)` | Create an analyzer by pairing `sorting` results with the respective `recording` and assign the resulting object to a variable `analyzer` |
| `analyzer.compute("extension_name")` | Compute an extension for the `analyzer` with a given name |
| `ext = analyzer.get_extension("extension_name")` | Get an extension from the `analyzer` and assign it to a variable `ext` |

TODO: Referennce all possible extensions (website?)
---

:::{#exm-}
Load the recoring extractor stored in the directory `"/preprocessed"` and the sorting results stored in the directory `"/results_TDC"`.
```{python}
rec = si.load_extractor("preprocessed")
sort = si.read_sorter_folder("results_TDC")
```
:::

:::{#exr-}
Load the spike sorting results stored in the directory `"/results_SPC"` and assign it to the variable `sort`.
:::
:::{sol.}
```{python}
sort = si.read_sorter_folder("results_SPC")
```
:::

:::{#exr-}
Create a sorting analyzer by pairing the sorting results `sort` and the recording `rec`.
:::
:::{sol.}
```{python}
analyzer = si.create_sorting_analyzer(sort, rec)
```
:::

:::{#exm-}
Randomly sample up to `300` spikes from every unit.
```{python}
analyzer.compute("random_spikes", method="uniform", max_spikes_per_unit=300)
```
:::

:::{#exm-}
Get the `"random_spikes"` extension from the `analyzer` and print the total number of spikes sampled.
```{python}
ext = analyzer.get_extension("random_spikes")
spike_indices = ext.get_data()
print("N_spikes = ", len(spike_indices))
```
:::

:::{#exr-}
Randomly sample up to `500` spikes per unit and print the total number of spikes sampled. 
:::
:::{sol.}
```{python}
analyzer.compute("random_spikes", method="uniform", max_spikes_per_unit=500)
ext = analyzer.get_extension("random_spikes")
spike_indices = ext.get_data()
print("N_spikes = ", len(spike_indices))
```
:::

:::{#exr-}
Randomly sample spikes and use `method="all"` to get **all** of the spikes (omit the `max_spikes_per_unit` argument). Then, print the total number of spikes sampled.
:::
:::{sol.}
```{python}
analyzer.compute("random_spikes", method="all")
ext = analyzer.get_extension("random_spikes")
spike_indices = ext.get_data()
print("N_spikes = ", len(spike_indices))
```
:::

:::{#exm-}
Compute the waveforms for all of the spikes using the signal between `2` milliseconds before and `3` milliseconds after each spike. 
```{python}
analyzer.compute("waveforms", ms_before=2, ms_after=3)
```
:::

:::{#exm-}
Get the `"waveforms"` extension from the `analyzer`, then get the array of waveforms for unit `3` and its `.shape` (dimensions represent spikes, samples and channels).
```{python}
ext = analyzer.get_extension("waveforms")
wfs = ext.get_waveforms_one_unit(unit_id=3)
wfs.shape
```
:::

:::{#exr-}
Compute the waveforms for all of the spikes using the signal between `1` millisecond before and `3` milliseconds after each spike. Then, get the waveforms for unit `3` and print their `.shape`.
:::
:::{sol.}
```{python}
analyzer.compute("waveforms", ms_before=1, ms_after=3)
ext = analyzer.get_extension("waveforms")
wfs = ext.get_waveforms_one_unit(unit_id=3)
wfs.shape
```
:::

:::{#exr-}
Compute the waveforms for all of the spikes using the signal between `1` millisecond before and `2` milliseconds after each spike. Then, get the waveforms for three different units and print their `.shape`.
:::
:::{sol.}
```{python}
analyzer.compute("waveforms", ms_before=1, ms_after=3)
ext = analyzer.get_extension("waveforms")
for unit_id in [5, 34, 103]:
    wfs = ext.get_waveforms_one_unit(unit_id=unit_id)
    print(wfs.shape)
```
:::

:::{#exm-}
Compute the `"templates"` for the extracted `"waveforms"` using the `"average"` operator.
```{python}
analyzer.compute("templates", operators=["average"])
```
:::

:::{#exm-}
Get the template for unit `3` and print its shape.
```{python}
ext = analyzer.get_extension("templates")
template = ext.get_unit_template(unit_id=3, operator="average")
template.shape
```
:::

:::{#exm-plot_template}
Get the `"ms_before"` and `"ms_after"` from `ext.params` and use it to create a vector of time points for the `template`. Then plot the `template` and label the axes.
```{python}
ms_before = ext.params["ms_before"]
ms_after = ext.params["ms_after"]
time_ms = np.linspace(start=-1 * ms_before, stop=ms_after, num=template.shape[0])
plt.plot(time_ms, template)
plt.xlabel("Time [ms]")
plt.ylabel("Voltage [muV]")
```
:::

:::{#exr-}
Plot the `template` for unit `10` as demonstrated in @exm-plot_template
:::
:::{sol.}
```{python}
template = ext.get_unit_template(unit_id=10, operator="average")
ms_before = ext.params["ms_before"]
ms_after = ext.params["ms_after"]
time_ms = np.linspace(start=-1 * ms_before, stop=ms_after, num=template.shape[0])
plt.plot(time_ms, template)
plt.xlabel("Time [ms]")
plt.ylabel("Voltage [muV]")
```
:::

:::{#exr-}
Compute the `"templates"` for the extracted `"waveforms"` using the `"median"` operator. Then, get the `template` for unit `10` and plot it.
:::
:::{sol.}
```{python}
analyzer.compute("templates", operators=["median"])
ext = analyzer.get_extension("templates")
template = ext.get_unit_template(unit_id=10, operator="median")
ms_before = ext.params["ms_before"]
ms_after = ext.params["ms_after"]
time_ms = np.linspace(start=-1 * ms_before, stop=ms_after, num=template.shape[0])
plt.plot(time_ms, template)
plt.xlabel("Time [ms]")
plt.ylabel("Voltage [muV]")
```
:::


## Localizing Detected Units

| Code | Description |
| --- | --- |
| `si.compute_unit_locations(analyzer, method)` | Compute unit locations for a given sorting `analyzer` with the given `method` |
| `ax = plt.subplot(projection='3d')` | Create a 3-dimensional plot and assign the returned axes object to a variable `ax` |
| `ax.scatter(x,y,z)` | Draw a scatter plot to the axes object `ax` |
| `ax.set(xlim=(-1,1), ylim=(-2,2))` | Set the x- and y-limits for `ax` |

---

:::{#exr-}
Run the cell below to create an interactive widget that shows, for each unit, the waveforms and the electrode locations where they were recorded. Select five different neurons and observe the corresponding waveforms. Can you infer the location of the units from the recorded waveforms?
```{python}
%matplotlib widget
si.plot_unit_waveforms(analyzer, backend="ipywidgets")
%matplotlib inline
```
:::

:::{#exm-}
Compute the unit locations using the `"center_of_mass"` method and print the shape of the returned `unit_locations`.
```{python}
unit_locations = si.compute_unit_locations(analyzer, method="center_of_mass")
unit_locations.shape
```
:::

:::{#exr-}
Compute the unit locations using the `"grid_convolution"` method and print the shape of the returned `unit_locations`.
:::
:::{sol.}
```{python}
unit_locations = si.compute_unit_locations(analyzer, method="monopolar_triangulation")
unit_locations.shape
```
:::

:::{#exr-}
Compute the unit locations using the `"monopolar_triangulation"` method and print the shape of the returned `unit_locations`.
:::
:::{sol.}
```{python}
unit_locations = si.compute_unit_locations(analyzer, method="monopolar_triangulation")
unit_locations.shape
```
:::

:::{#exm-}
Create a 3-dimensional scatter plot for the `unit_locations` computed with the `"monopolar_triangulation"` method (re-compute the locations if necessary). Use equal scaling on the x- and y-axis.
```{python}
# unit_locations = si.compute_unit_locations(analyzer, method="monopolar_triangulation")
x = unit_locations[:, 0]
y = unit_locations[:, 1]
z = unit_locations[:, 2]
ax = plt.subplot(projection='3d')
ax.scatter(x, y, z) # c=z colors by z-value
ax.set_xlim(-400, 400)
ax.set_ylim(0, 800)
```
:::

:::{#exr-}
Create a 3-dimensional scatter plot for the `unit_locations` computed with the `"grid_convolution"` method (re-compute the locations if necessary). Use equal scaling on the x- and y-axis.
:::
:::{sol.}
```{python}
unit_locations = si.compute_unit_locations(analyzer, method="grid_convolution")
x = unit_locations[:, 0]
y = unit_locations[:, 1]
z = unit_locations[:, 2]
ax = plt.subplot(projection='3d')
ax.scatter(x, y, z) # c=z colors by z-value
ax.set(xlim=(-400, 400), ylim=(0, 800))
```
:::

:::{#exr-}
Create a 2-dimensional scatter plot (without using `projection='3d'`) for the `unit_location` computed with the `"center_of_mass"` method (re-compute the locations if necessary). Use equal scaling
:::

```{python}
unit_locations = si.compute_unit_locations(analyzer, method="center_of_mass")
x = unit_locations[:, 0]
y = unit_locations[:, 1]
ax = plt.subplot()
ax.scatter(x, y)  # c=z colors by z-value
ax.set(xlim=(-400, 400), ylim=(0, 800))
```

## Curating Units with Quality Metrics

| Code | Description |
| --- | --- |
| `analyzer.compute(extension_name)` | Compute a given extension for the sorting `analyzer` (additional argments depend on the extension) |
| `ext=analyzer.get_extension(extension_name)` | Get the extension with the given name from the sorting `analyzer` |
| `ext.get_data()` | Get data for the extension `ext` |

---

:::{#exm-}
Compute the `"noise_levels"` and `"quality_metrics"` extension with the metrics `"snr"` and `"num_spikes"`.
```{python}
analyzer.compute("noise_levels")
analyzer.compute("quality_metrics", metric_names=["snr", "num_spikes"])
```
:::

:::{#exm-}
Extract the computed quality metrics for each unit as a pandas data frame and plot the `"snr"` as a histogram
```{python}
ext = analyzer.get_extension("quality_metrics")
df = ext.get_data()
plt.hist(df["snr"])
plt.xlabel("SNR")
plt.ylabel("Count")
```
:::

:::{#exr-}
Plot the number of spikes (`"num_spikes"`) as a histogram.
```{python}
plt.hist(df["num_spikes"])
plt.xlabel("Spike Count")
plt.ylabel("Count")
```
:::

:::{#exr-}
Compute the `"quality_metrics"` extension with the `"isi_violation"` metric. Then, extract the data frame and plot a histogram for the `"isi_violations_count"`.
:::
:::{sol.}
```{python}
analyzer.compute("quality_metrics", metric_names=["isi_violation"])
ext = analyzer.get_extension("quality_metrics")
df = ext.get_data()
plt.hist(df["isi_violations_count"])
plt.xlabel("ISI Violations")
plt.ylabel("Count")
```
:::

:::{#exr-}
Plot a histogram for the `"isi_violatios_ratio"` (HINT: you can use the `range` argument of the `plt.hist()` funtion to restrict the range of the histrogram bins to exclude outliers.
:::
:::{sol.}
```{python}
plt.hist(df["isi_violations_ratio"], range=(0,10))
plt.xlabel("ISI Violation Ratio")
plt.ylabel("Count")
```
:::

:::{#exm-}
Get the units with a SNR above 10.
```{python}
unit_ids = analyzer.unit_ids[df["snr"]>10]
unit_ids
```
:::

:::{#exm-}
Get the units with a SNR above 10 AND at least 200 recorded spikes.
```{python}
unit_ids = analyzer.unit_ids[(df["snr"]>10) & (df["num_spikes"]>=200)]
unit_ids
```
:::

:::{#exr-}
Get the units with an `"isi_violations_ratio"` below 4.
:::
:::{sol.}
```{python}
unit_ids = analyzer.unit_ids[(df["isi_violations_ratio"]<4)]
unit_ids
```
:::

:::{#exr-}
Get the units with an `"isi_violations_ratio"` below 3 AND at least 250 recorded spikes
:::
:::{sol.}
```{python}
unit_ids = analyzer.unit_ids[(df["isi_violations_ratio"]<3) & (df["num_spikes"]>=250)]
unit_ids
```
:::


:::{#exm-}
Select the curated unit_ids, save the new sorting object and load it for verification.
```{python}
sort_curated = sort.select_units(unit_ids=unit_ids)
sort_curated.save(folder="sorting_curated", overwrite=True)
si.load("sorting_curated")
```
:::

## Compare Different Sorters

| Code | Description |
| --- | --- | 
| `comp = si.compare_two_sorters(sorter1, sorter2, "name1", "name2")` | Compare two sorters with given names, returning a sorter comparison object |
| `si.plot_agreement_matrix(comp)` | Plot the agreement matrix for a given sorter comparison |
| `multi_comp = si.compare_multiple_sorters(sorter_list, name_list)` | Compare a list of multiple sorters (with a corresponding list of names), returning a multiple sorter comparison object |
| `si.plot_multicomparison_agreement(multi_comp)` | Plot a pie chart that displays the agreement between the sorters |
| `si.plot_multicomparison_agreement_by_sorter(multi_comp)` | Plot a pie chart that displays the agreement between the sorters separately for each sorter |


:::{#exm-}
Load the sorting results from Spikingcircus and Kilosort4 and assign them 
```{python}
sorting_SPC = si.read_sorter_folder("results_SPC")
sorting_KS4 = si.read_sorter_folder("results_KS4")
```
:::

:::{#exm-}
Compare the results from the Spikingcircus and Kilosort4 sorters using the `"count"` agreement methods and plot the agreement matrix. A clearly visible diagonal indicates that the sorters agree on a given unit.
```{python}
comp = si.compare_two_sorters(
    sorting_SPC, sorting_KS4, "Spikingcircus", "Kilosort4", agreement_method="count"
)
si.plot_agreement_matrix(comp, unit_ticks=False)
```
:::

:::{#exr-}
Compare the results from the Spikingcircus and Kilosort4  sorters using the `"distance"` agreement methods and plot the agreement matrix. 
:::
:::{sol.}
```{python}
comp = si.compare_two_sorters(
    sorting_SPC, sorting_KS4, "SPC", "KS4", agreement_method="distance"
)
si.plot_agreement_matrix(comp, unit_ticks=False)
```
:::

:::{#exr-}
Load the results from the Tridesclous sorter and compare them to the results from Spikingcircus by plotting the agreement matrix.
:::
:::{sol.}
```{python}
sorting_TDC = si.read_sorter_folder("results_TDC")
comp = si.compare_two_sorters(
    sorting_SPC, sorting_TDC, "Spikingcircus", "Tridesclous", agreement_method="count"
)
si.plot_agreement_matrix(comp, unit_ticks=False)
```
:::

:::{#exm-}
Compare the results from all three sorters using the `"count"` agreement method.
```{python}
multi_comp = si.compare_multiple_sorters(
    [sorting_SPC, sorting_KS4, sorting_TDC],
    ["Spikingcircus", "Kilosort4", "Tridesclous"],
    agreement_method="count",
)
```
:::

:::{#exm-}
Plot the mutlicomparison agreement.
```{python}
si.plot_multicomparison_agreement(multi_comp)
```
:::

:::{#exr-}
Compare the results from all three sorters using the `"distance"` agreement method.
:::
:::{sol.}
```{python}
multi_comp = si.compare_multiple_sorters(
    [sorting_SPC, sorting_KS4, sorting_TDC],
    ["Spikingcircus", "Kilosort4", "Tridesclous"],
    agreement_method="distance",
)
```
:::

:::{#exr-}
Plot the mutlicomparison agreement.
:::
:::{sol.}
```{python}
si.plot_multicomparison_agreement(multi_comp)
```
:::

:::{#exr-}
Plot the mutlicomparison agreement separately for each sorter.
:::
:::{sol.}
```{python}
si.plot_multicomparison_agreement_by_sorter(multi_comp)
```
:::