---
title: "Postprocessing and Curation with SpikeInterface"
engine: Jupyter
format: ipynb
filters:
    - assign
number-sections: true
number-depth: 2
---

## Preparation

Import the modules required for this notebook
```{python}
import numpy as np
from matplotlib import pyplot as plt
import spikeinterface.full as si
import probeinterface as pi
from probeinterface.plotting import plot_probe

%matplotlib inline
```

Download the data for this notebook (this may take a while)
```{python}
# | eval: false
import os
import zipfile
import requests

fnames = ["openephys_preprocessed", "results_KS4", "results_SPC", "results_TDC"]
urls = [
    "https://uni-bonn.sciebo.de/s/2LbWWs3VPVrQkLO",
    "https://uni-bonn.sciebo.de/s/26X6qhAAYq1uJfZ",
    "https://uni-bonn.sciebo.de/s/FnRPj7EQSYXFIEg",
    "https://uni-bonn.sciebo.de/s/EkdnDNhvF68HC9D",
]

for url, fname in zip(urls, fnames):
    print("downloading", fname)
    response = requests.get(f"{url}/download")
    with open(f"{fname}.zip", "wb") as file:
        file.write(response.content)

    with zipfile.ZipFile(f"{fname}.zip", "r") as zip_ref:
        zip_ref.extractall(".")
        extracted_name = zip_ref.namelist()[0].split("/")[0]
        if extracted_name != fname:
            os.rename(extracted_name, fname)
    os.remove(f"{fname}.zip")
print("Done!")
```

## Extracting Waveforms and Computing Templates

After spike sorting, we have the times when spikes occurred, but to validate and understand the sorted units, we need to examine their shapes. This process involves extracting the raw voltage "snippets" (waveforms) around each detected spike time. SpikeInterface streamlines this with the SortingAnalyzer object, a central hub that links a sorting result with its corresponding recording. In this section, you will learn how to create an analyzer and compute "extensions" like spike waveforms and average templates, which are the basis for all subsequent quality control and analysis.

| Code | Description |
|---|---|
| `rec = si.load_extractor("mydir")` | Load a recording extractor stored in the folder `"mydir"`. |
| `sorting = si.read_sorter_folder("results_SPC")` | Load spike sorting results from a folder. |
| `analyzer = si.create_sorting_analyzer(sorting, rec)` | Create an analyzer by pairing sorting results with the recording. |
| `analyzer.compute("random_spikes", **kwargs)` | Randomly sample spikes from each unit for efficient processing. |
| `analyzer.compute("waveforms", **kwargs)` | Extract spike waveforms for the sampled spikes. |
| `analyzer.compute("templates", **kwargs)` | Compute average templates from the extracted waveforms. |
| `ext = analyzer.get_extension("extension_name")` | Get a computed extension (e.g., "waveforms") from the analyzer. |
| `ext.get_data()` | Get the raw data from an extension object. |
| `ext.get_waveforms_one_unit(unit_id)` | Get the waveforms for a single specified unit. |
| `ext.get_unit_template(unit_id, operator)` | Get the template for a single unit (e.g., using "average" or "median"). |
| `plt.plot(template)` | Plot the average template waveform. |

---

Load the recoring extractor stored in the directory `"openephys_preprocessed"` and the sorting results stored in the directory `"results_SPC"` and create a sorting `analyzer`.
```{python}
rec = si.load("openephys_preprocessed")
sort = si.read_sorter_folder("results_SPC")
analyzer = si.create_sorting_analyzer(sort, rec)
```


:::{#exm-}
Randomly sample up to `300` spikes from every unit.
:::
```{python}
analyzer.compute("random_spikes", method="uniform", max_spikes_per_unit=300)
```

:::{#exm-}
Get the `"random_spikes"` extension from the `analyzer` and print the total number of spikes sampled.
:::
```{python}
ext = analyzer.get_extension("random_spikes")
spike_indices = ext.get_data()
print("N_spikes = ", len(spike_indices))
```

:::{#exr-}
Randomly sample up to `500` spikes per unit and print the total number of spikes sampled. 
:::
:::{.sol}
```{python}
analyzer.compute("random_spikes", method="uniform", max_spikes_per_unit=500)
ext = analyzer.get_extension("random_spikes")
spike_indices = ext.get_data()
print("N_spikes = ", len(spike_indices))
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Randomly sample spikes and use `method="all"` to get of the spikes (omit the `max_spikes_per_unit` argument). Then, print the total number of spikes sampled.
:::
:::{.sol}
```{python}
analyzer.compute("random_spikes", method="all")
ext = analyzer.get_extension("random_spikes")
spike_indices = ext.get_data()
print("N_spikes = ", len(spike_indices))
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exm-}
Compute the `"waveforms"` for all of the spikes using the `ms_before = 2` and `ms_after=3` milliseconds after each spike. 
:::
```{python}
analyzer.compute("waveforms", ms_before=2, ms_after=3)
```

:::{#exm-}
Get the `"waveforms"` extension from the `analyzer`, then get the array of waveforms for unit `3` and its `.shape` (dimensions represent spikes, samples and channels).
:::
```{python}
ext = analyzer.get_extension("waveforms")
wfs = ext.get_waveforms_one_unit(unit_id=3)
wfs.shape
```

:::{#exr-}
Compute the `"waveforms"` for all of the spikes using the `ms_before = 1` and `ms_after=2` milliseconds after each spike.  Then, get the waveforms for unit `3` and print their `.shape`.
:::
:::{.sol}
```{python}
analyzer.compute("waveforms", ms_before=1, ms_after=2)
ext = analyzer.get_extension("waveforms")
wfs = ext.get_waveforms_one_unit(unit_id=3)
wfs.shape
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::


:::{#exm-}
Compute the `"templates"` for the extracted `"waveforms"` using the `"average"` operator.
:::
```{python}
analyzer.compute("templates", operators=["average"])
```

:::{#exm-}
Get the `"average"` template for unit `3` and print its shape.
:::
```{python}
ext = analyzer.get_extension("templates")
template = ext.get_unit_template(unit_id=3, operator="average")
plt.plot(template);
```

:::{#exr-}
Compute the `"templates"` for the extracted `"waveforms"` using the `"median"` operator. 
:::
:::{.sol}
```{python}
analyzer.compute("templates", operators=["median"])
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Get the `"median"` template for unit `3` and print its shape.
:::
:::{.sol}
```{python}
ext = analyzer.get_extension("templates")
template = ext.get_unit_template(unit_id=3, operator="median")
plt.plot(template);
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::


## Localizing Detected Units

Knowing where a unit is physically located on the probe is crucial for validating sorting results (e.g., a single neuron should be localized in space) and for any spatial analysis of neural activity. SpikeInterface can estimate the position of each unit by analyzing the amplitude of its average waveform across the different electrode channels. In this section we will explore computing unit locations using various methods, such as "center of mass" and "monopolar triangulation," and visualizing these locations in 2D and 3D space relative to the probe geometry.

| Code | Description |
|---|---|
| `si.plot_unit_waveforms(analyzer, **kwargs)` | Create an interactive plot showing unit waveforms on the probe. |
| `unit_locations = si.compute_unit_locations(analyzer, method)` | Compute unit locations using a specified method (e.g., "center_of_mass"). |
| `probe = rec.get_probe()` | Retrieve the probe information from a recording object. |
| `plot_probe(probe)` | Plot the geometry of the probe. |
| `plt.scatter(x, y)` | Create a 2D scatter plot of x and y coordinates. |
| `ax = plt.subplot(projection='3d')` | Create a 3-dimensional plot axis. |
| `ax.scatter(x, y, z)` | Create a 3D scatter plot of x, y, and z coordinates. |
| `ax.set(xlim=..., ylim=...)` | Set the x and y axis limits for a plot. |

---

Run the cell below to create an interactive widget that shows, for each unit, the waveforms and the electrode locations where they were recorded.
```{python}
# | eval: false
%matplotlib widget
si.plot_unit_waveforms(analyzer, backend="ipywidgets")
%matplotlib inline
```

:::{#exm-}
Compute the unit locations using the `"center_of_mass"` method and print the shape of the returned `unit_locations`.
:::
```{python}
unit_locations = si.compute_unit_locations(analyzer, method="center_of_mass")
unit_locations.shape
```

:::{#exm-}
Get the probe from `rec` and plot it together with the `x` and `y` `unit_locations`.
:::
```{python}
probe = rec.get_probe()
plot_probe(probe)
x = unit_locations[:, 0]
y = unit_locations[:, 1]
plt.scatter(x, y)
plt.xlim(-400, 400)
plt.ylim(0, 800)
```

:::{#exr-}
Compute the unit locations using the `"monopolar_triangulation"` method and print the shape of the returned `unit_locations`.
:::
:::{.sol}
```{python}
unit_locations = si.compute_unit_locations(analyzer, method="monopolar_triangulation")
unit_locations.shape
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Plot the `probe` together with the `x` and `y` `unit_locations`.
:::
:::{.sol}
```{python}
probe = rec.get_probe()
plot_probe(probe)
x = unit_locations[:, 0]
y = unit_locations[:, 1]
plt.scatter(x, y)
plt.xlim(-400, 400)
plt.ylim(0, 800)
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exm-}
Create a 3D plot of the `x`, `y` and `z` `unit_locations`.
:::
```{python}
x = unit_locations[:, 0]
y = unit_locations[:, 1]
z = unit_locations[:, 2]
ax = plt.subplot(projection="3d")
ax.scatter(x, y, z)
ax.set(xlim=(-400, 400), ylim=(0, 800))
```

:::{#exr-}
Compute the unit locations using the `"grid_convolution"` method and print the shape of the returned `unit_locations`.
:::
:::{.sol}
```{python}
unit_locations = si.compute_unit_locations(analyzer, method="grid_convolution")
unit_locations.shape
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Create a 3D plot of the `x`, `y` and `z` `unit_locations`.
:::
:::{.sol}
```{python}
x = unit_locations[:, 0]
y = unit_locations[:, 1]
z = unit_locations[:, 2]
ax = plt.subplot(projection="3d")
ax.scatter(x, y, z)
ax.set(xlim=(-400, 400), ylim=(0, 800))
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::


## Curating Units with Quality Metrics

Spike sorting algorithms are not perfect; they often produce units that represent noise, artifacts, or a mix of multiple neurons (multi-unit activity). Therefore, a critical step in the workflow is to compute quality metrics to automatically curate the results and identify high-quality, well-isolated single units. SpikeInterface provides many metrics, including signal-to-noise ratio (SNR) and Inter-Spike Interval (ISI) violations. In this section, you will learn how to compute these metrics and use them to filter the sorting output, keeping only the units that meet your quality criteria.

| Code | Description |
|---|---|
| `analyzer.compute("noise_levels")` | Compute the noise level on each channel, a prerequisite for SNR. |
| `analyzer.compute("quality_metrics", metric_names=[...])` | Compute specified quality metrics for all units. |
| `ext = analyzer.get_extension("quality_metrics")` | Get the computed quality metrics from the analyzer. |
| `df = ext.get_data()` | Get the quality metrics as a pandas DataFrame. |
| `plt.hist(df["metric_name"])` | Plot a histogram of a specific quality metric's distribution. |
| `unit_ids = analyzer.unit_ids[df["metric_name"] > value]` | Select unit IDs that satisfy a condition based on a quality metric. |
| `curated_units = sort.select_units(unit_ids=unit_ids)` | Create a new, curated sorting object containing only the selected units. |
| `curated_units.save(folder="...", overwrite=True)` | Save the curated sorting results to a new folder. |

---

:::{#exm-}
Compute the `"noise_levels"` and `"quality_metrics"` extension with the metrics `"snr"` and `"num_spikes"`. Then, get the extension data and print the data frame.
:::
```{python}
analyzer.compute("noise_levels")
analyzer.compute("quality_metrics", metric_names=["snr", "num_spikes"])
ext = analyzer.get_extension("quality_metrics")
df = ext.get_data()
df
```

:::{#exr-}
Plot the distribution of `"snr"` in a histogram.
:::
:::{.sol}
```{python}
plt.hist(df["snr"])
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Compute the `"quality_metrics"` extension with the `"isi_violation"` metric, get the extension data and print the data frame. 
:::
:::{.sol}
```{python}
analyzer.compute("quality_metrics", metric_names=["isi_violation"])
ext = analyzer.get_extension("quality_metrics")
df = ext.get_data()
df
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Plot the distribution of `"isi_violation_count"` in a histogram.
:::
:::{.sol}
```{python}
plt.hist(df["isi_violations_count"])
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exm-}
Get the units with a SNR above 10.
:::
```{python}
unit_ids = analyzer.unit_ids[df["snr"]>10]
unit_ids
```

:::{#exr-}
Get the units with an `"isi_violations_ratio"` below 4.
:::
:::{.sol}
```{python}
unit_ids = analyzer.unit_ids[(df["isi_violations_ratio"]<4)]
unit_ids
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Use `sort.select_units` to select the filtered `unit_ids` and return the `curated_units`. Then use `curated_units.save()` to save them.
:::
:::{.sol}
```{python}
curated_units = sort.select_units(unit_ids=unit_ids)
curated_units.save(folder="sorting_curated", overwrite=True)
si.load("sorting_curated")
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

## Compare Different Sorters

Different spike sorters use different algorithms and may produce different results on the same dataset. By comparing the outputs of multiple sorters, we can identify a "consensus" set of units found by all (or most) of them, which increases our confidence in their validity. This comparison also highlights where sorters disagree, pointing to units that may be difficult to sort or require manual inspection. SpikeInterface provides convenient tools to compare sorters and visualize their agreement. In this section, you will learn how to compare sorters and interpret the resulting agreement matrices and summary plots.

| Code | Description |
|---|---|
| `comp = si.compare_two_sorters(...)` | Compare two sorters, returning a comparison object. |
| `si.plot_agreement_matrix(comp, **kwargs)` | Plot the agreement matrix for a pairwise sorter comparison. |
| `multi_comp = si.compare_multiple_sorters(...)` | Compare a list of multiple sorters, returning a multi-comparison object. |
| `si.plot_multicomparison_agreement(multi_comp)` | Plot a pie chart summarizing the agreement between multiple sorters. |
| `si.plot_multicomparison_agreement_by_sorter(multi_comp)` | Plot agreement summaries broken down by each individual sorter. |

Load the sorting results from Spykingcircus, Kilosort4 and Tridesclous.
```{python}
sorting_SPC = si.read_sorter_folder("results_SPC")
sorting_KS4 = si.read_sorter_folder("results_KS4")
sorting_TDC = si.read_sorter_folder("results_TDC")
```

:::{#exm-}
Compare the results from the Spikingcircus and Kilosort4 sorters using the `"count"` agreement methods and plot the agreement matrix. A clearly visible diagonal indicates that the sorters agree on a given unit.
:::
```{python}
comp = si.compare_two_sorters(
    sorting_SPC, sorting_KS4, "Spikingcircus", "Kilosort4", agreement_method="count"
)
si.plot_agreement_matrix(comp, unit_ticks=False)
```

:::{#exr-}
Compare the results from the Spikingcircus and Kilosort4  sorters using the `"distance"` agreement methods and plot the agreement matrix. 
:::
:::{.sol}
```{python}
comp = si.compare_two_sorters(
    sorting_SPC, sorting_KS4, "SPC", "KS4", agreement_method="distance"
)
si.plot_agreement_matrix(comp, unit_ticks=False)
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Load the results from the Tridesclous sorter and compare them to the results from Spikingcircus by plotting the agreement matrix.
:::
:::{.sol}
```{python}
sorting_TDC = si.read_sorter_folder("results_TDC")
comp = si.compare_two_sorters(
    sorting_SPC, sorting_TDC, "Spikingcircus", "Tridesclous", agreement_method="count"
)
si.plot_agreement_matrix(comp, unit_ticks=False)
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exm-}
Compare the results from all three sorters using the `"count"` agreement method.
:::
```{python}
multi_comp = si.compare_multiple_sorters(
    [sorting_SPC, sorting_KS4, sorting_TDC],
    ["Spikingcircus", "Kilosort4", "Tridesclous"],
    agreement_method="count",
)
```

:::{#exr-}
Use `si.plot_multicomparison_agreement` to plot the `multi_comp`.
:::
:::{.sol}
```{python}
si.plot_multicomparison_agreement(multi_comp)
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Compare the results from all three sorters using the `"distance"` agreement method.
:::
:::{.sol}
```{python}
multi_comp = si.compare_multiple_sorters(
    [sorting_SPC, sorting_KS4, sorting_TDC],
    ["Spikingcircus", "Kilosort4", "Tridesclous"],
    agreement_method="distance",
)
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Plot the mutlicomparison agreement.
:::
:::{.sol}
```{python}
si.plot_multicomparison_agreement(multi_comp)
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::

:::{#exr-}
Plot the mutlicomparison agreement separately for each sorter.
:::
:::{.sol}
```{python}
si.plot_multicomparison_agreement_by_sorter(multi_comp)
```
:::
:::{.direction}
```{python}
#| echo: false
print('​')
```
:::