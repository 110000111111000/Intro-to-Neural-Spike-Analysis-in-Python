---
title: "Estimating Receptive Field Maps"
engine: Jupyter
format: ipynb
filters:
    - assign
execute: 
  cache: true
number-sections: true
number-depth: 2
---

## Preparation

Import the modules required for this notebook
```{python}
from pathlib import Path
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
```

Download the data
```{python}
import os
import requests
import zipfile

url = "https://uni-bonn.sciebo.de/s/FV84Gvj3ZKHPN4Z"
fname = "allen"

if not os.path.exists("../data"):
    os.mkdir("../data")

if not os.path.exists(f"../data/{fname}"):
    response = requests.get(f"{url}/download")
    with open(f"{fname}.zip", "wb") as file:
        file.write(response.content)

    with zipfile.ZipFile(f"{fname}.zip", "r") as zip_ref:
        zip_ref.extractall(f"../data/{fname}")
        os.remove(f"{fname}.zip")
```



:::{.sol}

```{python}
stimuli
```
```{python}
session = "ses-778240327"
stimuli = pd.read_parquet(f"../data/allen/{session}/gabor_stimuli.parquet")
spikes = pd.read_parquet(f"../data/allen/{session}/gabor_spikes.parquet")
stimuli.head(5)
```
:::


```{python}
import seaborn as sns
result = stimuli.groupby(['y_position', 'x_position']).size().unstack()
sns.heatmap(result);
```

```{python}
df = stimuli.copy()
fun = lambda trial: (spikes[(spikes.spike_time >= trial.start_time) & (spikes.spike_time <= trial.stop_time)]).spike_time.round(4).tolist()
df['spikes'] = df.apply(fun, axis=1)

df
```



```{python}
result = df.explode('spikes').groupby(['y_position', 'x_position']).spikes.count().unstack()
sns.heatmap(result);
```



```{python}
df = stimuli.copy()
fun = lambda trial: (spikes[(spikes.spike_time >= trial.start_time) & (spikes.spike_time <= trial.stop_time)])
dd = df.iloc[:20].apply(fun, axis=1)
dd
```

```{python}
df2 = df.iloc[:20].copy()
df2['spikedata'] = dd.tolist()
df2
```



##############


```{python}
### Don't run--too slow.
# spikes2 = spikes.copy()
# # time = spikes2.iloc[0].spike_time
# fun = lambda time: stimuli[(stimuli.start_time <= time) & (time <= stimuli.stop_time)].index[0]
# spikes2['stimulus_id'] = spikes2.spike_time.apply(fun)
# spikes2
```


```{python}
merged = pd.merge_asof(
    spikes,
    stimuli,
    left_on='spike_time',
    right_on='start_time',
    direction='backward'
)
merged

```


```{python}
sns.heatmap(merged.groupby(['y_position', 'x_position']).size().unstack());
```


```{python}
g = sns.FacetGrid(data=merged, col='orientation')
fun = lambda data, *args, **kwargs: sns.heatmap(data.groupby(['y_position', 'x_position']).size().unstack())
g.map_dataframe(fun)
```


```{python}
g = sns.FacetGrid(data=merged, row='brain_area', col='orientation')
g.map_dataframe(lambda data, *args, **kwargs: sns.heatmap(data.groupby(['y_position', 'x_position']).size().unstack()))
```


```{python}
import plotly.express as px
fig = px.density_heatmap(
    merged, x='x_position', y='y_position',
    facet_row='brain_area', facet_col='orientation'
)
fig.show()

```